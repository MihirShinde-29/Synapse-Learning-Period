{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "KFjs9O1ix1Wf"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "drlb8xGSYFx6"
   },
   "source": [
    "## Introduction to open cv\n",
    "\n",
    "1. video resources\n",
    " - https://www.youtube.com/watch?v=oXlwWbU8l2o\n",
    " - https://www.youtube.com/watch?v=N81PCpADwKQ\n",
    "\n",
    "2. instructions to access video resources\n",
    " - the video resources are very long\n",
    " - no need to go through them in the beginning (we'll try to cover the important parts in this notebook)\n",
    " - whenever you feel stuck during the task, you can come back to the videos and look for relevant time stamps in the video descriptions. \n",
    "\n",
    "3. General instructions\n",
    " - play around with arguments of algorithms\n",
    " - if not mentioned, then use the latest downloaded image for all following tasks.\n",
    " - this week getting an intuition is more important than the mathematical theory behind the algorithms so understand their use cases and their application"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Y3PYF7ooY0ol"
   },
   "source": [
    "## Import open cv "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "yUcwgAofYFU3"
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'cv2'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-c8ec22b3e787>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'cv2'"
     ]
    }
   ],
   "source": [
    "import cv2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pjBE_IghY5zA"
   },
   "source": [
    "## Downloading image for image processing using wget\n",
    "1. wget is a linux xommand that helps us download content from the web\n",
    "2. we can use the -O flag to store it using a custom name\n",
    "3. all linux commands can be accessed in jupyter notebooks using ! before the command"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5-Tcrx8CY5gI"
   },
   "outputs": [],
   "source": [
    "!wget -O learn.jpg https://encrypted-tbn0.gstatic.com/images?q=tbn:ANd9GcTrqWUxvjvW1PfKP4HLmhEG4fN4x1qEbPD3qw&usqp=CAU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "f6Pk2gv-Y5WR",
    "outputId": "f4d26ec9-a057-43c4-bd37-5d7aca6244ae"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "edge.jpg\t hough.png  marble.jpg\t       sample_data\n",
      "houghlines5.jpg  learn.jpg  preprocessing.jpg\n"
     ]
    }
   ],
   "source": [
    "# linux command to see files in current directory\n",
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "hrZ4qFxbcIeg"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PExLfAIycILA"
   },
   "source": [
    "## Read an image using open cv\n",
    " - images read using opencv are converted into a pixel matrix which we can use.\n",
    " - all images are made up of pixels but more on that later"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "32FXxeGKY4qE"
   },
   "outputs": [],
   "source": [
    "#write code to read image using opencv (google)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "id": "oQP7bjbHbX67"
   },
   "outputs": [],
   "source": [
    "#we will use plt from matplotlib to see the images (plt.imshow)\n",
    "#remember to cvt colour as open cv saves image in Blue Green Red, while we see it in Red Green Blue\n",
    "\n",
    "#example code\n",
    "#plt.imshow(cv2.cvtColor(<name of your image variable after reading it>, cv2.COLOR_BGR2RGB))\n",
    "\n",
    "#write code here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "QZFyNTopc1Iw"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "D7g3msWWde0e"
   },
   "source": [
    "## Acessing individual pixels and analyzing the image\n",
    "\n",
    "Resource : <br>\n",
    "https://www.analyticsvidhya.com/blog/2021/03/grayscale-and-rgb-format-for-storing-images/\n",
    "\n",
    "Each value in the BGR 3-tuple has a range of [0, 255] . <br>\n",
    "How many color possibilities are there for each pixel in an RGB image in OpenCV?<br>\n",
    " Thatâ€™s easy: 256 * 256 * 256 = 16777216 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7PtXSjNhhRA3"
   },
   "source": [
    "1. Read the image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "0IyOkj1YhP7i"
   },
   "outputs": [],
   "source": [
    "#write code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bwH2CzAQd8gG"
   },
   "source": [
    "2. printing the read image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "id": "jXSzEgp7d7pj"
   },
   "outputs": [],
   "source": [
    "#write code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6eLGUe3ueDnV"
   },
   "source": [
    "we see that it is a matrix of pixels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GgWIfFbzdwMj"
   },
   "source": [
    "3. getting the shape of the image (google)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "id": "frjLksYmc1CC"
   },
   "outputs": [],
   "source": [
    "#write code to get shape here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NiLRwyesePle"
   },
   "source": [
    "we see that it is a 3 dimensional matrix of the shape n,m,c\n",
    " - n is the height\n",
    " - m is the width\n",
    " - c is the number of channels (The Blue Green and Red channels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ks5olCwBjTHp"
   },
   "source": [
    "3. Accessing individual pixels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "id": "-Qp6FFXmk2Zg"
   },
   "outputs": [],
   "source": [
    "#since it is a list of lists we can use indexing\n",
    "#let's access the pixel at height 50, width 35 and in the red channel (remember that open cv saves image in BGR) -> im[50][35][2]\n",
    "\n",
    "#write code here\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "zKfnks_LelPU",
    "outputId": "aff3e67c-cd34-4d39-9ee1-22101993111d"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "'\\n(B, G, R) = <name of your image variable>[100, 50]\\nprint(\"R={}, G={}, B={}\".format(R, G, B))\\n'"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#access the BGR pixels located at x=100, y=50\n",
    "'''\n",
    "(B, G, R) = <name of your image variable>[100, 50]\n",
    "print(\"R={}, G={}, B={}\".format(R, G, B))\n",
    "'''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "HNYQHw-sc0lq"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bOtaEVGImhCh"
   },
   "source": [
    "## Resizing images\n",
    "- use cv2.resize() to resize your image to (200,200) and then show it using plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "id": "WtnocduvmgwA"
   },
   "outputs": [],
   "source": [
    "#write code here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "TNqdqL_PnkTt"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uquXonnMnlUs"
   },
   "source": [
    "## Crop images\n",
    " - cropping the image from height 70 to 150 and width 50 to 120"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "EKBAi8Flnlvj",
    "outputId": "964dfd4d-d4c2-4265-99f7-99e0e0ab9e9e"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "'\\nexample code : \\nimg[x_start:x_end , y_start:y_end]\\n\\nwe can use commas to slice from each dimension in a multidimension array\\n'"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "example code : \n",
    "img[x_start:x_end , y_start:y_end]\n",
    "\n",
    "we can use commas to slice from each dimension in a multidimension array\n",
    "'''\n",
    "\n",
    "#write code here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "jNlSaMLfpro5"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FZIxHnLdpr5v"
   },
   "source": [
    "## Draw images and write text on image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8MLq7eSdpdrI"
   },
   "outputs": [],
   "source": [
    "#draw a circle rectangle and a straight line \n",
    "#use cv2.circle cv2.rectangle cv2.line eg:\n",
    "\n",
    "#code for drawing circle given below\n",
    "\n",
    "im = #enter your image variable name here and put a .copy() suffix so that it is stored elsewhere in the memory\n",
    "\n",
    "op = im.copy() #makes a copy of the entire image in memory and stores it in op\n",
    "cv2.circle(op, (100, 100), 10, (0, 255, 0), -1)\n",
    "plt.imshow(cv2.cvtColor(op, cv2.COLOR_BGR2RGB))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mwjSIJDzqJKQ"
   },
   "source": [
    "#### Code explanation\n",
    "op : The output image.\n",
    "\n",
    "center : Our circleâ€™s center coordinate. (100, 100).\n",
    "\n",
    "radius : The circle radius in pixels. 10 pixels.\n",
    "\n",
    "color : Circle color : green, which is denoted by 255 in the g and 0s in the B + R components of the BGR tuple, (0, 255, 0) .\n",
    "\n",
    "thickness : The line thickness. a negative value (-1 ) means that the circle is solid/filled in."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wM-jFiw3GDf3"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NBONzVYSGD1X"
   },
   "source": [
    " - now write a similar code for drawing a square and line being of colors blue and red respectively (google for the parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "id": "DMllwbR9qC9M"
   },
   "outputs": [],
   "source": [
    "#square code here\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "id": "roe9QmJ4qq9P"
   },
   "outputs": [],
   "source": [
    "#line code here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3nD6quAuGLty"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EU66XjuSqtx_"
   },
   "source": [
    "## Convert image to grayscale\n",
    " - google the one line code to do this in open cv and convert the downloaded image to grayscale / black and white\n",
    " - plot the image using plt.imshow()\n",
    " - remember to set the colour map to \"gray\" (cmap=\"gray) in plt.imshow() as plt automatically adds a colour filter which is not needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "id": "7c8o62EFqq6i"
   },
   "outputs": [],
   "source": [
    "#write code here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "SFhVUsw9qqyp"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mBNlFDrDwC91"
   },
   "source": [
    "## Filter/Kernel/Convolution Operations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6oVhcI2mwTKB"
   },
   "source": [
    "1. Defining a kernel operation - https://www.youtube.com/watch?v=Etksi-F5ug8\n",
    "  - watch the above video and understand what a convolution operation is\n",
    "  - Write a function that applies any kernel convolution to any image input (pass kernel and image as arguments).\n",
    "  - assume that the image is grayscale so there is only one channel instead of the usual RBG channels\n",
    "  - note that kernels will always be a square matrix while an image can be of any shape\n",
    "  - hint : use slicing to prevent for loops while performing addition operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "id": "TBrp9ZjMwCW6"
   },
   "outputs": [],
   "source": [
    "def convolution(kernel, image):\n",
    "  #override this function and replace pass with a return statement\n",
    "  pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "R4_R0Rel0ejG"
   },
   "source": [
    "#### kernel\n",
    "$$\n",
    "\\left(\\begin{array}{cc} \n",
    "1 & 2\\\\\n",
    "3 & 4\n",
    "\\end{array}\\right)\n",
    "$$ \n",
    "<br>\n",
    "\n",
    "#### image\n",
    "$$\n",
    "\\left(\\begin{array}{cc} \n",
    "1 & 1 & 0 & 0 & 0\\\\\n",
    "1 & 1 & 0 & 0 & 0\\\\\n",
    "1 & 1 & 0 & 0 & 0\\\\\n",
    "1 & 1 & 0 & 0 & 0\\\\\n",
    "\\end{array}\\right)\n",
    "$$ \n",
    "\n",
    "#### output\n",
    "$$\n",
    "\\left(\\begin{array}{cc} \n",
    "10 & 4 & 0 & 0\\\\\n",
    "10 & 4 & 0 & 0\\\\\n",
    "10 & 4 & 0 & 0\\\\\n",
    "\\end{array}\\right)\n",
    "$$ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "id": "GHcbIhY6yfyP"
   },
   "outputs": [],
   "source": [
    "#unit test to check convolution function\n",
    "#this function must give the output as mentioned in the matrix above\n",
    "convolution( np.array([[1,2], [3,4]]) , np.array([[1,1,0,0,0], [1,1,0,0,0], [1,1,0,0,0], [1,1,0,0,0]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "id": "qKrtS9tVTYSZ"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CWQWAq9NK2VV"
   },
   "source": [
    "2. Vertical Edge detection using kernel operations\n",
    " - such convolution operations can help us do a lot of image processing\n",
    " - Edge detection can be done using one such kernel\n",
    " - download the image https://image.shutterstock.com/image-photo/brown-wooden-fence-isolated-on-260nw-1935567586.jpg using wget\n",
    " - kernel to be used : -\n",
    "$$\n",
    "\\left(\\begin{array}{cc} \n",
    "1 & 0 & -1\\\\\n",
    "2 & 0 & -2\\\\\n",
    "1 & 0 & -1\\\\\n",
    "\\end{array}\\right)\n",
    "$$ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "id": "fzKxktDiK1Np"
   },
   "outputs": [],
   "source": [
    "#downloading the image and saving it as edge.jpg\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "id": "8385yn0BQswd"
   },
   "outputs": [],
   "source": [
    "#see files in current directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "id": "xY3PUpzWRLbP"
   },
   "outputs": [],
   "source": [
    "#read the image using cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "id": "eZkG71hIReAi"
   },
   "outputs": [],
   "source": [
    "#convert to grayscale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "id": "dmKdWtHcRvj7"
   },
   "outputs": [],
   "source": [
    "#show the grayscale image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "id": "YVz6UUBSSlbv"
   },
   "outputs": [],
   "source": [
    "# apply convolution operation on this image to perform edge detection.\n",
    "#use the function you made previosuly\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "id": "AysvjLMiTI9y"
   },
   "outputs": [],
   "source": [
    "#imshow the new image after applying the convolution operation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "xdzG-ODtsK8u"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WQYUyZDVsLQm"
   },
   "source": [
    " - apply edge filter on the learn.jpg that we downloaded earlier\n",
    "  - see that the horizontal lines are not detected at all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "id": "Po3_6TMWTl3C"
   },
   "outputs": [],
   "source": [
    "#write code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "w7_fo36jv0H9"
   },
   "source": [
    "## Additional convolution Operations\n",
    "\n",
    "1. convolution operation with padding -> https://www.youtube.com/watch?v=PGBop7Ka9AU\n",
    "2. convolution operation with strides -> https://www.youtube.com/watch?v=lxk_nmpqI5M\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6CLz0IkkVKcj"
   },
   "source": [
    "Try implementing a convolution function with padding and stride in parameters as well as a challenge activity.\n",
    "\n",
    "<b>Note that this is optional</b> - (we will implement this using tensorflow next week)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "id": "mirLNNxZvxoB"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Vp0-9ymOtDj_"
   },
   "source": [
    "## Blurring\n",
    " - Blurring is used to reduce noise in the image\n",
    " - it is based on the convolution operations that we did"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1WpNvspxuQKh"
   },
   "source": [
    "1. download the image https://encrypted-tbn0.gstatic.com/images?q=tbn:ANd9GcQgswCFmbTpJmErjtFi_oOL8Q87v4W3jUQEDw&usqp=CAU using wget (save it as preprocessing.jpg)\n",
    "\n",
    "2. read and show the image\n",
    "\n",
    "3. apply cv2's  gaussian and meidan blur on the image using cv2 and show it in the notebook (google)\n",
    "\n",
    "4. refer the following video for theory reference : https://www.youtube.com/watch?v=C_zFhWdM4ic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "id": "7nz0Ejeatu9V"
   },
   "outputs": [],
   "source": [
    "#download image here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "id": "3fkMARWUu8L7"
   },
   "outputs": [],
   "source": [
    "#read and show the image here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "id": "WLmUN2gou_pL"
   },
   "outputs": [],
   "source": [
    "# Gaussian Blur"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "id": "n9cgcdTYvP7_"
   },
   "outputs": [],
   "source": [
    "# Median Blur"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "id": "eGJ0srndfQ9d"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XVIX8aI_guck"
   },
   "source": [
    "## Edge detection using open cv\n",
    " - convert to black and white\n",
    " - apply gaussian blurr to remove noise \n",
    " - apply canny edge detector on the blurred image (google)\n",
    "\n",
    "Canny edge detector was built upon the previously developed sobel operators<br>\n",
    "theory references : <br>\n",
    " - https://www.youtube.com/watch?v=H4kKKU2_tJM\n",
    " - https://www.youtube.com/watch?v=3RxuHYheL4w\n",
    "\n",
    "Code reference : <br>\n",
    " - https://learnopencv.com/edge-detection-using-opencv/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "id": "eNyn2JSLgw-4"
   },
   "outputs": [],
   "source": [
    "#write code here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "id": "E6aMaIZShw1E"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "89uy1rrNh3TI"
   },
   "source": [
    "## Hough Transform\n",
    " - helps detect lines in the image and gives the equation for them\n",
    " - we will use the probablistic hough transform\n",
    "\n",
    "Download https://image.shutterstock.com/image-vector/straight-road-white-markings-way-260nw-1718754808.jpg using wget (store as hough.png)\n",
    "<br><br>\n",
    "show the image using plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "id": "Vv079EpMjLLd"
   },
   "outputs": [],
   "source": [
    "#download image here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "id": "0viAmmAfjO-i"
   },
   "outputs": [],
   "source": [
    "#read and show image here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AdPyvKO0mcr6"
   },
   "source": [
    " ### Instructions :\n",
    " - Part 1\n",
    "  - convert to black and white\n",
    "  - apply gaussian blurr to remove noise\n",
    "  - apply the canny edge detector to detect edges\n",
    "  - apply hough transform to get the lines from the canny edge (google) (play with the threshold argument)\n",
    "  - draw lines on the original image using cv2.line\n",
    "  - show it using plt.imshow\n",
    "\n",
    "- Part 2\n",
    "  - get all the lines found in the image and remove all lines with slope in the range [-0.3, 0.3].\n",
    "  - draw lines on the image using cv2.line\n",
    "  - show it using plt.imshow\n",
    "\n",
    "- Part 2 removes all the horizontal lines detected from the image and keeps all the vertically inclined lines which we might be interested in. (Imagine the use case of such an algorithm for driverless cars)\n",
    "\n",
    "<br>\n",
    "\n",
    "Theory reference : https://www.youtube.com/watch?v=4zHbI-fFIlI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "id": "P16l0dyqsQQU"
   },
   "outputs": [],
   "source": [
    "#part 1 code here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "id": "aGDyXUAvjTjb"
   },
   "outputs": [],
   "source": [
    "#part 2 code here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "id": "1jH6IzxYj2GJ"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XkYPiuHI8l3P"
   },
   "source": [
    "## Binarization\n",
    "- converting image into pure black and pure white (binary)\n",
    "- download image https://d27bba62iw3ft5.cloudfront.net/spree/images/153278/product/1610374692098-ATEMNY-_0002_LAAOPO-02120210122-24-y7fuvt.jpg using wget (save it as marble.jpg)\n",
    "- show the image using plt.imshow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "id": "b9rOTj9P9DhW"
   },
   "outputs": [],
   "source": [
    "#download image here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "id": "O3GPr5uJ9Kz3"
   },
   "outputs": [],
   "source": [
    "#read and show image here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "chISMBqx9y9a"
   },
   "source": [
    "#### Instructions\n",
    "- Part 1\n",
    " - convert to black and white\n",
    " - binarize using otsu threshold (google)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "id": "-KAXOXVQ9bHK"
   },
   "outputs": [],
   "source": [
    "#convert to black and white and show image here "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "id": "G6ZdMfdG-Gmh"
   },
   "outputs": [],
   "source": [
    "#binarize and show image here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OmbZdYPf-ghT"
   },
   "source": [
    "If you have binarized correctly, you should get an output similar to this -:    \n",
    "\n",
    "![]( https://drive.google.com/uc?id=159-tToBBBxhWPPiHu-gmoT-xUe7Ci9pu \"Text to show on mouseover\")\n",
    "\n",
    "<br>\n",
    "\n",
    "Let's say we have to recognize the marble which here is circular. However there is some white noise.<br>\n",
    "\n",
    "To fix this we have to use something called as morphological transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "id": "s82lgpWfAv20"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JmIpp3UU_-S5"
   },
   "source": [
    "## Morphological Transformations\n",
    "- reference video : https://www.youtube.com/watch?v=xSzsD4kXhRw&t=960s\n",
    "- go throught the above video carefully\n",
    "- apply appropriate morphological transformations to eradicate the white spot\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "id": "rqnj4liyALxb"
   },
   "outputs": [],
   "source": [
    "#write code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XRgGXquYCJti"
   },
   "source": [
    "##### Explain in short why you used the chosen morphological transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "Ney_SHtaB8GG",
    "outputId": "2b4cb744-be15-4226-c620-cbff4dfbbe1a"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "'\\n## begin answer ##\\n\\n## end answer ##\\n'"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#write explaination here in the string comments\n",
    "\n",
    "'''\n",
    "## begin answer ##\n",
    "\n",
    "## end answer ##\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TWrDdHrRH-t7"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "week6.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
